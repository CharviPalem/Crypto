{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "824fc0f7",
   "metadata": {},
   "source": [
    "# FHE Training Demo\n",
    "\n",
    "This notebook demonstrates Fully Homomorphic Encryption (FHE) training and inference using Concrete-ML.\n",
    "\n",
    "## Overview\n",
    "- Load preprocessed medical data\n",
    "- Train Concrete-ML logistic regression model\n",
    "- Run encrypted inference on test data\n",
    "- Compare clear vs encrypted predictions visually\n",
    "- Display confusion matrix heatmap for analysis\n",
    "\n",
    "## Key Features\n",
    "- **Privacy-Preserving ML**: Train models that can operate on encrypted data\n",
    "- **Performance Comparison**: Clear vs encrypted accuracy analysis\n",
    "- **Visual Analysis**: Comprehensive plots and confusion matrices\n",
    "- **Real-world Application**: Medical data classification with privacy protection\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc1c356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "\n",
    "# Add the src directory to Python path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Try to import Concrete-ML (with fallback)\n",
    "try:\n",
    "    from concrete.ml.sklearn import LogisticRegression as FHELogisticRegression\n",
    "    CONCRETE_ML_AVAILABLE = True\n",
    "    print(\"‚úÖ Concrete-ML available for FHE operations\")\n",
    "except ImportError:\n",
    "    from sklearn.linear_model import LogisticRegression as FHELogisticRegression\n",
    "    CONCRETE_ML_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è Concrete-ML not available, using sklearn for demonstration\")\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"üìö All imports successful!\")\n",
    "print(f\"üîê FHE Mode: {'Enabled' if CONCRETE_ML_AVAILABLE else 'Simulation'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df7fcc7",
   "metadata": {},
   "source": [
    "## 1. Load Preprocessed Data\n",
    "\n",
    "Load the preprocessed medical data for FHE training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33534652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data\n",
    "data_path = Path('../data/processed/preprocessed_data.json')\n",
    "\n",
    "if data_path.exists():\n",
    "    print(f\"üìÇ Loading preprocessed data from: {data_path}\")\n",
    "    with open(data_path, 'r', encoding='utf-8') as f:\n",
    "        preprocessed_data = json.load(f)\n",
    "    \n",
    "    records = preprocessed_data.get('processed_records', [])\n",
    "    print(f\"‚úÖ Loaded {len(records)} preprocessed records\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Preprocessed data not found. Creating synthetic data for demonstration...\")\n",
    "    \n",
    "    # Create synthetic preprocessed data\n",
    "    np.random.seed(42)\n",
    "    n_samples = 500\n",
    "    \n",
    "    conditions = ['diabetes', 'hypertension', 'heart_disease', 'asthma', 'arthritis']\n",
    "    age_groups = ['18-30', '31-50', '51-65', '65+']\n",
    "    \n",
    "    records = []\n",
    "    for i in range(n_samples):\n",
    "        condition = np.random.choice(conditions)\n",
    "        record = {\n",
    "            'patient_id': f'patient_{i:04d}',\n",
    "            'age_group': np.random.choice(age_groups),\n",
    "            'medical_notes_processed': f\"Patient presents with {condition} symptoms and related complications\",\n",
    "            'primary_condition': condition,\n",
    "            'risk_score': np.random.uniform(0.1, 0.9),\n",
    "            'anonymized': True\n",
    "        }\n",
    "        records.append(record)\n",
    "    \n",
    "    print(f\"‚úÖ Created {len(records)} synthetic records for demonstration\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "print(f\"üìä DataFrame shape: {df.shape}\")\n",
    "print(f\"üìã Columns: {list(df.columns)}\")\n",
    "\n",
    "# Display basic info\n",
    "print(\"\\nüìà Data Overview:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e6657b",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing for ML\n",
    "\n",
    "Prepare the data for machine learning by extracting features and encoding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012f012d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and labels\n",
    "print(\"üîß Preparing features and labels for ML training...\")\n",
    "\n",
    "# Extract text features using TF-IDF\n",
    "print(\"üìù Extracting text features from medical notes...\")\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=100,  # Limit features for FHE compatibility\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2\n",
    ")\n",
    "\n",
    "# Vectorize medical notes\n",
    "X_text = vectorizer.fit_transform(df['medical_notes_processed']).toarray()\n",
    "print(f\"üìä Text features shape: {X_text.shape}\")\n",
    "\n",
    "# Add numerical features if available\n",
    "numerical_features = []\n",
    "if 'risk_score' in df.columns:\n",
    "    numerical_features.append(df['risk_score'].values.reshape(-1, 1))\n",
    "    print(\"üìà Added risk score as numerical feature\")\n",
    "\n",
    "# Encode age groups as numerical features\n",
    "if 'age_group' in df.columns:\n",
    "    age_encoder = LabelEncoder()\n",
    "    age_encoded = age_encoder.fit_transform(df['age_group']).reshape(-1, 1)\n",
    "    numerical_features.append(age_encoded)\n",
    "    print(\"üéÇ Added encoded age group as numerical feature\")\n",
    "\n",
    "# Combine all features\n",
    "if numerical_features:\n",
    "    X_numerical = np.hstack(numerical_features)\n",
    "    X = np.hstack([X_text, X_numerical])\n",
    "    print(f\"üîó Combined features shape: {X.shape}\")\n",
    "else:\n",
    "    X = X_text\n",
    "    print(f\"üìä Using text features only: {X.shape}\")\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['primary_condition'])\n",
    "\n",
    "print(f\"üè∑Ô∏è Labels encoded: {len(label_encoder.classes_)} classes\")\n",
    "print(f\"üìã Classes: {list(label_encoder.classes_)}\")\n",
    "print(f\"üéØ Label distribution:\")\n",
    "for i, class_name in enumerate(label_encoder.classes_):\n",
    "    count = np.sum(y == i)\n",
    "    print(f\"   {class_name}: {count} samples ({count/len(y)*100:.1f}%)\")\n",
    "\n",
    "# Scale features for better FHE performance\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(f\"‚öñÔ∏è Features scaled to mean=0, std=1\")\n",
    "print(f\"üìä Final feature matrix shape: {X_scaled.shape}\")\n",
    "print(f\"üéØ Final label vector shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2799a34",
   "metadata": {},
   "source": [
    "## 3. Train-Test Split\n",
    "\n",
    "Split the data into training and testing sets for model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c3b0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, \n",
    "    test_size=0.3, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"üìä Data Split Summary:\")\n",
    "print(f\"   Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"   Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"   Features: {X_train.shape[1]} dimensions\")\n",
    "print(f\"   Classes: {len(label_encoder.classes_)}\")\n",
    "\n",
    "# Display class distribution in train/test sets\n",
    "print(\"\\nüéØ Training Set Distribution:\")\n",
    "train_unique, train_counts = np.unique(y_train, return_counts=True)\n",
    "for class_idx, count in zip(train_unique, train_counts):\n",
    "    class_name = label_encoder.classes_[class_idx]\n",
    "    print(f\"   {class_name}: {count} samples ({count/len(y_train)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nüéØ Test Set Distribution:\")\n",
    "test_unique, test_counts = np.unique(y_test, return_counts=True)\n",
    "for class_idx, count in zip(test_unique, test_counts):\n",
    "    class_name = label_encoder.classes_[class_idx]\n",
    "    print(f\"   {class_name}: {count} samples ({count/len(y_test)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n‚úÖ Data preparation completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4807c0",
   "metadata": {},
   "source": [
    "## 4. Train Clear (Non-Encrypted) Model\n",
    "\n",
    "First, train a standard logistic regression model for baseline comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c871576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train clear (non-encrypted) logistic regression model\n",
    "print(\"üîì Training Clear Logistic Regression Model...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Initialize and train clear model\n",
    "clear_model = LogisticRegression(\n",
    "    random_state=42,\n",
    "    max_iter=1000,\n",
    "    multi_class='ovr'  # One-vs-Rest for multi-class\n",
    ")\n",
    "\n",
    "clear_model.fit(X_train, y_train)\n",
    "clear_training_time = time.time() - start_time\n",
    "\n",
    "print(f\"‚úÖ Clear model training completed in {clear_training_time:.2f} seconds\")\n",
    "\n",
    "# Make predictions on test set\n",
    "start_time = time.time()\n",
    "y_pred_clear = clear_model.predict(X_test)\n",
    "clear_inference_time = time.time() - start_time\n",
    "\n",
    "# Calculate accuracy\n",
    "clear_accuracy = accuracy_score(y_test, y_pred_clear)\n",
    "\n",
    "print(f\"üéØ Clear Model Performance:\")\n",
    "print(f\"   Training time: {clear_training_time:.2f} seconds\")\n",
    "print(f\"   Inference time: {clear_inference_time:.4f} seconds\")\n",
    "print(f\"   Test accuracy: {clear_accuracy:.4f} ({clear_accuracy*100:.2f}%)\")\n",
    "\n",
    "# Display detailed classification report\n",
    "print(f\"\\nüìä Detailed Classification Report (Clear Model):\")\n",
    "class_names = label_encoder.classes_\n",
    "print(classification_report(y_test, y_pred_clear, target_names=class_names, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baef122",
   "metadata": {},
   "source": [
    "## 5. Train Concrete-ML FHE Model\n",
    "\n",
    "Train the FHE-compatible logistic regression model using Concrete-ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f21fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train FHE-compatible logistic regression model\n",
    "print(\"üîê Training FHE Logistic Regression Model...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Initialize FHE model with appropriate parameters\n",
    "if CONCRETE_ML_AVAILABLE:\n",
    "    fhe_model = FHELogisticRegression(\n",
    "        n_bits=8,  # Quantization bits for FHE compatibility\n",
    "        random_state=42,\n",
    "        max_iter=100  # Reduced for FHE efficiency\n",
    "    )\n",
    "    print(\"üîê Using Concrete-ML FHE Logistic Regression\")\n",
    "else:\n",
    "    fhe_model = FHELogisticRegression(\n",
    "        random_state=42,\n",
    "        max_iter=1000,\n",
    "        multi_class='ovr'\n",
    "    )\n",
    "    print(\"‚ö†Ô∏è Using sklearn Logistic Regression (simulation mode)\")\n",
    "\n",
    "# Train the FHE model\n",
    "fhe_model.fit(X_train, y_train)\n",
    "fhe_training_time = time.time() - start_time\n",
    "\n",
    "print(f\"‚úÖ FHE model training completed in {fhe_training_time:.2f} seconds\")\n",
    "\n",
    "# Compile the model for FHE inference (if Concrete-ML is available)\n",
    "if CONCRETE_ML_AVAILABLE:\n",
    "    print(\"üîß Compiling model for FHE inference...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Use a subset of training data for compilation\n",
    "        X_compile = X_train[:100]  # Use smaller subset for faster compilation\n",
    "        fhe_model.compile(X_compile)\n",
    "        compilation_time = time.time() - start_time\n",
    "        print(f\"‚úÖ FHE compilation completed in {compilation_time:.2f} seconds\")\n",
    "        FHE_COMPILED = True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è FHE compilation failed: {e}\")\n",
    "        print(\"üìù Continuing with simulation mode...\")\n",
    "        FHE_COMPILED = False\n",
    "        compilation_time = 0\n",
    "else:\n",
    "    FHE_COMPILED = False\n",
    "    compilation_time = 0\n",
    "\n",
    "print(f\"\\nüìä FHE Model Training Summary:\")\n",
    "print(f\"   Training time: {fhe_training_time:.2f} seconds\")\n",
    "print(f\"   Compilation time: {compilation_time:.2f} seconds\")\n",
    "print(f\"   FHE mode: {'Enabled' if FHE_COMPILED else 'Simulation'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcebe62e",
   "metadata": {},
   "source": [
    "## 6. Run Encrypted Inference\n",
    "\n",
    "Perform inference on encrypted test data and compare with clear predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0193fb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run encrypted inference\n",
    "print(\"üîê Running Encrypted Inference...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "if FHE_COMPILED and CONCRETE_ML_AVAILABLE:\n",
    "    print(\"üîê Performing true FHE encrypted inference...\")\n",
    "    \n",
    "    # Use a smaller subset for encrypted inference (due to computational cost)\n",
    "    n_encrypted_samples = min(50, len(X_test))\n",
    "    X_test_encrypted = X_test[:n_encrypted_samples]\n",
    "    y_test_encrypted = y_test[:n_encrypted_samples]\n",
    "    \n",
    "    print(f\"üìä Running encrypted inference on {n_encrypted_samples} samples...\")\n",
    "    \n",
    "    try:\n",
    "        # Perform encrypted inference\n",
    "        y_pred_encrypted = fhe_model.predict(X_test_encrypted, fhe=\"execute\")\n",
    "        fhe_inference_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"‚úÖ Encrypted inference completed in {fhe_inference_time:.2f} seconds\")\n",
    "        print(f\"‚ö° Average time per sample: {fhe_inference_time/n_encrypted_samples:.4f} seconds\")\n",
    "        \n",
    "        # Calculate encrypted accuracy\n",
    "        encrypted_accuracy = accuracy_score(y_test_encrypted, y_pred_encrypted)\n",
    "        \n",
    "        # Also get clear predictions for the same subset for comparison\n",
    "        y_pred_clear_subset = clear_model.predict(X_test_encrypted)\n",
    "        clear_subset_accuracy = accuracy_score(y_test_encrypted, y_pred_clear_subset)\n",
    "        \n",
    "        print(f\"\\nüéØ Encrypted Inference Results:\")\n",
    "        print(f\"   Samples processed: {n_encrypted_samples}\")\n",
    "        print(f\"   Encrypted accuracy: {encrypted_accuracy:.4f} ({encrypted_accuracy*100:.2f}%)\")\n",
    "        print(f\"   Clear accuracy (same subset): {clear_subset_accuracy:.4f} ({clear_subset_accuracy*100:.2f}%)\")\n",
    "        print(f\"   Accuracy difference: {abs(encrypted_accuracy - clear_subset_accuracy):.4f}\")\n",
    "        \n",
    "        ENCRYPTED_INFERENCE_SUCCESS = True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Encrypted inference failed: {e}\")\n",
    "        print(\"üìù Falling back to simulation mode...\")\n",
    "        ENCRYPTED_INFERENCE_SUCCESS = False\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Running simulation mode (clear inference)...\")\n",
    "    ENCRYPTED_INFERENCE_SUCCESS = False\n",
    "\n",
    "# If encrypted inference failed or not available, use clear inference for comparison\n",
    "if not ENCRYPTED_INFERENCE_SUCCESS:\n",
    "    print(\"üîÑ Using FHE model in simulation mode...\")\n",
    "    \n",
    "    # Use the FHE model but in clear mode\n",
    "    y_pred_fhe_clear = fhe_model.predict(X_test)\n",
    "    fhe_clear_inference_time = time.time() - start_time\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    fhe_clear_accuracy = accuracy_score(y_test, y_pred_fhe_clear)\n",
    "    \n",
    "    print(f\"‚úÖ FHE model (simulation) inference completed in {fhe_clear_inference_time:.4f} seconds\")\n",
    "    print(f\"üéØ FHE model (simulation) accuracy: {fhe_clear_accuracy:.4f} ({fhe_clear_accuracy*100:.2f}%)\")\n",
    "    \n",
    "    # Use these predictions for comparison\n",
    "    y_pred_encrypted = y_pred_fhe_clear\n",
    "    encrypted_accuracy = fhe_clear_accuracy\n",
    "    n_encrypted_samples = len(X_test)\n",
    "\n",
    "print(f\"\\nüìä Inference Performance Summary:\")\n",
    "if ENCRYPTED_INFERENCE_SUCCESS:\n",
    "    print(f\"   Mode: True FHE Encryption\")\n",
    "    print(f\"   Samples: {n_encrypted_samples}\")\n",
    "    print(f\"   Time: {fhe_inference_time:.2f} seconds\")\n",
    "    print(f\"   Speed: {n_encrypted_samples/fhe_inference_time:.2f} samples/second\")\n",
    "else:\n",
    "    print(f\"   Mode: Simulation\")\n",
    "    print(f\"   Samples: {n_encrypted_samples}\")\n",
    "    print(f\"   Time: {fhe_clear_inference_time:.4f} seconds\")\n",
    "    print(f\"   Speed: {n_encrypted_samples/fhe_clear_inference_time:.0f} samples/second\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c2f248",
   "metadata": {},
   "source": [
    "## 7. Visual Comparison: Clear vs Encrypted Predictions\n",
    "\n",
    "Compare the predictions from clear and encrypted models visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e51230f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visual comparison of clear vs encrypted predictions\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Clear vs Encrypted Model Comparison', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Prepare data for comparison\n",
    "if ENCRYPTED_INFERENCE_SUCCESS:\n",
    "    # Use the subset that was actually encrypted\n",
    "    comparison_true = y_test_encrypted\n",
    "    comparison_clear = y_pred_clear_subset\n",
    "    comparison_encrypted = y_pred_encrypted\n",
    "    comparison_samples = n_encrypted_samples\n",
    "else:\n",
    "    # Use full test set for simulation comparison\n",
    "    comparison_true = y_test\n",
    "    comparison_clear = y_pred_clear\n",
    "    comparison_encrypted = y_pred_encrypted\n",
    "    comparison_samples = len(y_test)\n",
    "\n",
    "# 1. Accuracy Comparison Bar Chart\n",
    "models = ['Clear Model', 'FHE Model']\n",
    "accuracies = [accuracy_score(comparison_true, comparison_clear), \n",
    "              accuracy_score(comparison_true, comparison_encrypted)]\n",
    "\n",
    "bars = ax1.bar(models, accuracies, color=['skyblue', 'lightcoral'], alpha=0.8, edgecolor='black')\n",
    "ax1.set_title('Model Accuracy Comparison', fontweight='bold')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "             f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 2. Prediction Agreement Analysis\n",
    "agreement = (comparison_clear == comparison_encrypted)\n",
    "agreement_rate = np.mean(agreement)\n",
    "\n",
    "agreement_labels = ['Agree', 'Disagree']\n",
    "agreement_counts = [np.sum(agreement), np.sum(~agreement)]\n",
    "colors = ['lightgreen', 'lightcoral']\n",
    "\n",
    "wedges, texts, autotexts = ax2.pie(agreement_counts, labels=agreement_labels, \n",
    "                                   autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "ax2.set_title(f'Prediction Agreement\\n({agreement_rate:.1%} agreement)', fontweight='bold')\n",
    "\n",
    "for autotext in autotexts:\n",
    "    autotext.set_color('white')\n",
    "    autotext.set_fontweight('bold')\n",
    "\n",
    "# 3. Class-wise Accuracy Comparison\n",
    "class_accuracies_clear = []\n",
    "class_accuracies_encrypted = []\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    class_mask = (comparison_true == i)\n",
    "    if np.sum(class_mask) > 0:\n",
    "        clear_class_acc = accuracy_score(comparison_true[class_mask], comparison_clear[class_mask])\n",
    "        encrypted_class_acc = accuracy_score(comparison_true[class_mask], comparison_encrypted[class_mask])\n",
    "    else:\n",
    "        clear_class_acc = 0\n",
    "        encrypted_class_acc = 0\n",
    "    \n",
    "    class_accuracies_clear.append(clear_class_acc)\n",
    "    class_accuracies_encrypted.append(encrypted_class_acc)\n",
    "\n",
    "x_pos = np.arange(len(class_names))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax3.bar(x_pos - width/2, class_accuracies_clear, width, \n",
    "                label='Clear Model', color='skyblue', alpha=0.8)\n",
    "bars2 = ax3.bar(x_pos + width/2, class_accuracies_encrypted, width,\n",
    "                label='FHE Model', color='lightcoral', alpha=0.8)\n",
    "\n",
    "ax3.set_title('Class-wise Accuracy Comparison', fontweight='bold')\n",
    "ax3.set_xlabel('Medical Conditions')\n",
    "ax3.set_ylabel('Accuracy')\n",
    "ax3.set_xticks(x_pos)\n",
    "ax3.set_xticklabels(class_names, rotation=45, ha='right')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 4. Sample Predictions Visualization\n",
    "sample_indices = np.arange(min(20, comparison_samples))\n",
    "sample_true = comparison_true[:len(sample_indices)]\n",
    "sample_clear = comparison_clear[:len(sample_indices)]\n",
    "sample_encrypted = comparison_encrypted[:len(sample_indices)]\n",
    "\n",
    "# Create a scatter plot showing prediction differences\n",
    "ax4.scatter(sample_indices, sample_true, label='True Labels', \n",
    "           marker='o', s=100, alpha=0.7, color='green')\n",
    "ax4.scatter(sample_indices, sample_clear, label='Clear Predictions', \n",
    "           marker='^', s=80, alpha=0.7, color='blue')\n",
    "ax4.scatter(sample_indices, sample_encrypted, label='FHE Predictions', \n",
    "           marker='s', s=80, alpha=0.7, color='red')\n",
    "\n",
    "ax4.set_title(f'Sample Predictions Comparison\\n(First {len(sample_indices)} samples)', fontweight='bold')\n",
    "ax4.set_xlabel('Sample Index')\n",
    "ax4.set_ylabel('Predicted Class')\n",
    "ax4.set_yticks(range(len(class_names)))\n",
    "ax4.set_yticklabels(class_names)\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed comparison statistics\n",
    "print(\"üìä Detailed Comparison Statistics:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"üìà Overall Accuracy:\")\n",
    "print(f\"   Clear Model: {accuracies[0]:.4f} ({accuracies[0]*100:.2f}%)\")\n",
    "print(f\"   FHE Model: {accuracies[1]:.4f} ({accuracies[1]*100:.2f}%)\")\n",
    "print(f\"   Difference: {abs(accuracies[0] - accuracies[1]):.4f}\")\n",
    "\n",
    "print(f\"\\nü§ù Prediction Agreement:\")\n",
    "print(f\"   Agreement Rate: {agreement_rate:.4f} ({agreement_rate*100:.2f}%)\")\n",
    "print(f\"   Agreeing Predictions: {np.sum(agreement)}/{comparison_samples}\")\n",
    "print(f\"   Disagreeing Predictions: {np.sum(~agreement)}/{comparison_samples}\")\n",
    "\n",
    "print(f\"\\nüìã Class-wise Performance:\")\n",
    "for i, class_name in enumerate(class_names):\n",
    "    print(f\"   {class_name}:\")\n",
    "    print(f\"      Clear: {class_accuracies_clear[i]:.3f}\")\n",
    "    print(f\"      FHE: {class_accuracies_encrypted[i]:.3f}\")\n",
    "    print(f\"      Diff: {abs(class_accuracies_clear[i] - class_accuracies_encrypted[i]):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a305fd",
   "metadata": {},
   "source": [
    "## 8. Confusion Matrix Heatmaps\n",
    "\n",
    "Display detailed confusion matrices for both clear and encrypted models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1e6775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix heatmaps\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.suptitle('Confusion Matrix Comparison: Clear vs FHE Models', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Calculate confusion matrices\n",
    "cm_clear = confusion_matrix(comparison_true, comparison_clear)\n",
    "cm_encrypted = confusion_matrix(comparison_true, comparison_encrypted)\n",
    "\n",
    "# Create heatmaps\n",
    "sns.heatmap(cm_clear, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names,\n",
    "            ax=ax1, cbar_kws={'label': 'Count'})\n",
    "ax1.set_title(f'Clear Model Confusion Matrix\\nAccuracy: {accuracies[0]:.3f}', fontweight='bold')\n",
    "ax1.set_xlabel('Predicted Label')\n",
    "ax1.set_ylabel('True Label')\n",
    "\n",
    "sns.heatmap(cm_encrypted, annot=True, fmt='d', cmap='Reds',\n",
    "            xticklabels=class_names, yticklabels=class_names,\n",
    "            ax=ax2, cbar_kws={'label': 'Count'})\n",
    "ax2.set_title(f'FHE Model Confusion Matrix\\nAccuracy: {accuracies[1]:.3f}', fontweight='bold')\n",
    "ax2.set_xlabel('Predicted Label')\n",
    "ax2.set_ylabel('True Label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and display detailed metrics for each class\n",
    "print(\"üìä Detailed Performance Metrics by Class:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Calculate metrics for clear model\n",
    "precision_clear, recall_clear, f1_clear, support_clear = precision_recall_fscore_support(\n",
    "    comparison_true, comparison_clear, average=None, labels=range(len(class_names))\n",
    ")\n",
    "\n",
    "# Calculate metrics for encrypted model\n",
    "precision_encrypted, recall_encrypted, f1_encrypted, support_encrypted = precision_recall_fscore_support(\n",
    "    comparison_true, comparison_encrypted, average=None, labels=range(len(class_names))\n",
    ")\n",
    "\n",
    "# Create a detailed comparison table\n",
    "print(f\"{'Class':<15} {'Model':<10} {'Precision':<10} {'Recall':<10} {'F1-Score':<10} {'Support':<10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    print(f\"{class_name:<15} {'Clear':<10} {precision_clear[i]:<10.3f} {recall_clear[i]:<10.3f} {f1_clear[i]:<10.3f} {support_clear[i]:<10}\")\n",
    "    print(f\"{'':<15} {'FHE':<10} {precision_encrypted[i]:<10.3f} {recall_encrypted[i]:<10.3f} {f1_encrypted[i]:<10.3f} {support_encrypted[i]:<10}\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "# Calculate macro and weighted averages\n",
    "precision_clear_macro = np.mean(precision_clear)\n",
    "recall_clear_macro = np.mean(recall_clear)\n",
    "f1_clear_macro = np.mean(f1_clear)\n",
    "\n",
    "precision_encrypted_macro = np.mean(precision_encrypted)\n",
    "recall_encrypted_macro = np.mean(recall_encrypted)\n",
    "f1_encrypted_macro = np.mean(f1_encrypted)\n",
    "\n",
    "print(f\"{'MACRO AVG':<15} {'Clear':<10} {precision_clear_macro:<10.3f} {recall_clear_macro:<10.3f} {f1_clear_macro:<10.3f} {np.sum(support_clear):<10}\")\n",
    "print(f\"{'MACRO AVG':<15} {'FHE':<10} {precision_encrypted_macro:<10.3f} {recall_encrypted_macro:<10.3f} {f1_encrypted_macro:<10.3f} {np.sum(support_encrypted):<10}\")\n",
    "\n",
    "# Additional confusion matrix analysis\n",
    "print(f\"\\nüîç Confusion Matrix Analysis:\")\n",
    "print(f\"Clear Model:\")\n",
    "print(f\"   True Positives (diagonal): {np.trace(cm_clear)}\")\n",
    "print(f\"   Total Predictions: {np.sum(cm_clear)}\")\n",
    "print(f\"   Correct Predictions: {np.trace(cm_clear)}/{np.sum(cm_clear)}\")\n",
    "\n",
    "print(f\"FHE Model:\")\n",
    "print(f\"   True Positives (diagonal): {np.trace(cm_encrypted)}\")\n",
    "print(f\"   Total Predictions: {np.sum(cm_encrypted)}\")\n",
    "print(f\"   Correct Predictions: {np.trace(cm_encrypted)}/{np.sum(cm_encrypted)}\")\n",
    "\n",
    "# Calculate per-class error analysis\n",
    "print(f\"\\n‚ùå Error Analysis:\")\n",
    "for i, class_name in enumerate(class_names):\n",
    "    clear_errors = np.sum(cm_clear[i, :]) - cm_clear[i, i]\n",
    "    encrypted_errors = np.sum(cm_encrypted[i, :]) - cm_encrypted[i, i]\n",
    "    print(f\"   {class_name}: Clear={clear_errors} errors, FHE={encrypted_errors} errors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b21d43",
   "metadata": {},
   "source": [
    "## 9. Performance and Privacy Analysis\n",
    "\n",
    "Analyze the trade-offs between performance, privacy, and computational cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0b4c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance and Privacy Analysis\n",
    "print(\"üîç Performance and Privacy Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create performance comparison visualization\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('FHE Performance and Privacy Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Training Time Comparison\n",
    "training_times = [clear_training_time, fhe_training_time]\n",
    "training_labels = ['Clear Model', 'FHE Model']\n",
    "\n",
    "bars = ax1.bar(training_labels, training_times, color=['skyblue', 'lightcoral'], alpha=0.8)\n",
    "ax1.set_title('Training Time Comparison', fontweight='bold')\n",
    "ax1.set_ylabel('Time (seconds)')\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for bar, time_val in zip(bars, training_times):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(training_times)*0.01,\n",
    "             f'{time_val:.2f}s', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 2. Inference Time Comparison\n",
    "if ENCRYPTED_INFERENCE_SUCCESS:\n",
    "    inference_times = [clear_inference_time/len(X_test), fhe_inference_time/n_encrypted_samples]\n",
    "    inference_labels = ['Clear Model\\n(per sample)', 'FHE Model\\n(per sample)']\n",
    "else:\n",
    "    inference_times = [clear_inference_time/len(X_test), fhe_clear_inference_time/len(X_test)]\n",
    "    inference_labels = ['Clear Model\\n(per sample)', 'FHE Model\\n(simulation, per sample)']\n",
    "\n",
    "bars = ax2.bar(inference_labels, inference_times, color=['lightgreen', 'orange'], alpha=0.8)\n",
    "ax2.set_title('Inference Time Comparison', fontweight='bold')\n",
    "ax2.set_ylabel('Time per Sample (seconds)')\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for bar, time_val in zip(bars, inference_times):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(inference_times)*0.01,\n",
    "             f'{time_val:.4f}s', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 3. Privacy vs Utility Trade-off\n",
    "privacy_levels = ['No Privacy\\n(Clear)', 'Full Privacy\\n(FHE)']\n",
    "utility_scores = [accuracies[0], accuracies[1]]\n",
    "privacy_scores = [0, 100]  # Privacy score (0 = no privacy, 100 = full privacy)\n",
    "\n",
    "# Create dual-axis plot\n",
    "ax3_twin = ax3.twinx()\n",
    "\n",
    "line1 = ax3.plot(privacy_levels, utility_scores, 'bo-', linewidth=2, markersize=8, label='Utility (Accuracy)')\n",
    "line2 = ax3_twin.plot(privacy_levels, privacy_scores, 'ro-', linewidth=2, markersize=8, label='Privacy Level')\n",
    "\n",
    "ax3.set_title('Privacy vs Utility Trade-off', fontweight='bold')\n",
    "ax3.set_ylabel('Accuracy', color='blue')\n",
    "ax3_twin.set_ylabel('Privacy Level (%)', color='red')\n",
    "ax3.tick_params(axis='y', labelcolor='blue')\n",
    "ax3_twin.tick_params(axis='y', labelcolor='red')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, (util, priv) in enumerate(zip(utility_scores, privacy_scores)):\n",
    "    ax3.text(i, util + 0.01, f'{util:.3f}', ha='center', va='bottom', color='blue', fontweight='bold')\n",
    "    ax3_twin.text(i, priv + 2, f'{priv}%', ha='center', va='bottom', color='red', fontweight='bold')\n",
    "\n",
    "# 4. Model Complexity Comparison\n",
    "complexity_metrics = ['Features', 'Parameters', 'Model Size (KB)']\n",
    "\n",
    "# Estimate model complexity (simplified)\n",
    "n_features = X_train.shape[1]\n",
    "n_classes = len(class_names)\n",
    "clear_params = n_features * n_classes + n_classes  # weights + biases\n",
    "fhe_params = clear_params  # Same model architecture\n",
    "\n",
    "# Estimate model sizes (simplified)\n",
    "clear_size = clear_params * 8 / 1024  # 8 bytes per parameter, convert to KB\n",
    "fhe_size = clear_params * 8 / 1024 + 10  # Additional overhead for FHE\n",
    "\n",
    "complexity_clear = [n_features, clear_params, clear_size]\n",
    "complexity_fhe = [n_features, fhe_params, fhe_size]\n",
    "\n",
    "x_pos = np.arange(len(complexity_metrics))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax4.bar(x_pos - width/2, complexity_clear, width, label='Clear Model', color='skyblue', alpha=0.8)\n",
    "bars2 = ax4.bar(x_pos + width/2, complexity_fhe, width, label='FHE Model', color='lightcoral', alpha=0.8)\n",
    "\n",
    "ax4.set_title('Model Complexity Comparison', fontweight='bold')\n",
    "ax4.set_xlabel('Complexity Metrics')\n",
    "ax4.set_ylabel('Count / Size')\n",
    "ax4.set_xticks(x_pos)\n",
    "ax4.set_xticklabels(complexity_metrics)\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print comprehensive analysis\n",
    "print(\"\\nüìä Comprehensive Performance Analysis:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "print(f\"üèÉ Training Performance:\")\n",
    "print(f\"   Clear Model: {clear_training_time:.2f} seconds\")\n",
    "print(f\"   FHE Model: {fhe_training_time:.2f} seconds\")\n",
    "print(f\"   Overhead: {(fhe_training_time/clear_training_time - 1)*100:.1f}% slower\")\n",
    "\n",
    "print(f\"\\n‚ö° Inference Performance:\")\n",
    "if ENCRYPTED_INFERENCE_SUCCESS:\n",
    "    speedup_factor = (fhe_inference_time/n_encrypted_samples) / (clear_inference_time/len(X_test))\n",
    "    print(f\"   Clear Model: {clear_inference_time/len(X_test):.6f} seconds/sample\")\n",
    "    print(f\"   FHE Model: {fhe_inference_time/n_encrypted_samples:.6f} seconds/sample\")\n",
    "    print(f\"   Overhead: {speedup_factor:.0f}x slower\")\n",
    "else:\n",
    "    print(f\"   Clear Model: {clear_inference_time/len(X_test):.6f} seconds/sample\")\n",
    "    print(f\"   FHE Model (sim): {fhe_clear_inference_time/len(X_test):.6f} seconds/sample\")\n",
    "\n",
    "print(f\"\\nüéØ Accuracy Analysis:\")\n",
    "print(f\"   Clear Model: {accuracies[0]:.4f}\")\n",
    "print(f\"   FHE Model: {accuracies[1]:.4f}\")\n",
    "print(f\"   Accuracy Loss: {(accuracies[0] - accuracies[1]):.4f} ({((accuracies[0] - accuracies[1])/accuracies[0]*100):.2f}%)\")\n",
    "\n",
    "print(f\"\\nüîí Privacy Benefits:\")\n",
    "print(f\"   Data Privacy: {'‚úÖ Full encryption' if ENCRYPTED_INFERENCE_SUCCESS else '‚ö†Ô∏è Simulation mode'}\")\n",
    "print(f\"   Model Privacy: {'‚úÖ Encrypted inference' if ENCRYPTED_INFERENCE_SUCCESS else '‚ö†Ô∏è Clear inference'}\")\n",
    "print(f\"   Compliance: {'‚úÖ GDPR/HIPAA compatible' if ENCRYPTED_INFERENCE_SUCCESS else '‚ö†Ô∏è Limited compliance'}\")\n",
    "\n",
    "print(f\"\\nüí∞ Cost-Benefit Analysis:\")\n",
    "print(f\"   Accuracy Trade-off: {abs(accuracies[0] - accuracies[1]):.4f} accuracy loss\")\n",
    "print(f\"   Privacy Gain: {'100% data privacy' if ENCRYPTED_INFERENCE_SUCCESS else 'Simulation only'}\")\n",
    "print(f\"   Computational Cost: {'High (true FHE)' if ENCRYPTED_INFERENCE_SUCCESS else 'Low (simulation)'}\")\n",
    "print(f\"   Recommendation: {'Suitable for high-privacy applications' if ENCRYPTED_INFERENCE_SUCCESS else 'Good for development/testing'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188dd92b",
   "metadata": {},
   "source": [
    "## 10. Summary and Conclusions\n",
    "\n",
    "Summary of the FHE training demonstration and key insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddad317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results and generate summary\n",
    "output_dir = Path('../data/results')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save model comparison results\n",
    "results_summary = {\n",
    "    \"experiment_info\": {\n",
    "        \"timestamp\": pd.Timestamp.now().isoformat(),\n",
    "        \"dataset_size\": len(df),\n",
    "        \"features\": X_train.shape[1],\n",
    "        \"classes\": len(class_names),\n",
    "        \"test_samples\": comparison_samples,\n",
    "        \"fhe_mode\": \"encrypted\" if ENCRYPTED_INFERENCE_SUCCESS else \"simulation\"\n",
    "    },\n",
    "    \"model_performance\": {\n",
    "        \"clear_model\": {\n",
    "            \"accuracy\": float(accuracies[0]),\n",
    "            \"training_time\": float(clear_training_time),\n",
    "            \"inference_time_per_sample\": float(clear_inference_time/len(X_test))\n",
    "        },\n",
    "        \"fhe_model\": {\n",
    "            \"accuracy\": float(accuracies[1]),\n",
    "            \"training_time\": float(fhe_training_time),\n",
    "            \"inference_time_per_sample\": float(fhe_inference_time/n_encrypted_samples if ENCRYPTED_INFERENCE_SUCCESS else fhe_clear_inference_time/len(X_test)),\n",
    "            \"compilation_time\": float(compilation_time)\n",
    "        }\n",
    "    },\n",
    "    \"comparison_metrics\": {\n",
    "        \"accuracy_difference\": float(abs(accuracies[0] - accuracies[1])),\n",
    "        \"prediction_agreement_rate\": float(agreement_rate),\n",
    "        \"privacy_level\": \"high\" if ENCRYPTED_INFERENCE_SUCCESS else \"simulation\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save results to JSON\n",
    "results_file = output_dir / 'fhe_training_demo_results.json'\n",
    "with open(results_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(results_summary, f, indent=2)\n",
    "\n",
    "print(\"üíæ Results saved to:\", results_file)\n",
    "\n",
    "# Generate comprehensive summary\n",
    "print(\"\\nüéâ FHE Training Demo Summary\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"üìä Dataset Information:\")\n",
    "print(f\"   Total Records: {len(df)}\")\n",
    "print(f\"   Features: {X_train.shape[1]}\")\n",
    "print(f\"   Classes: {len(class_names)} ({', '.join(class_names)})\")\n",
    "print(f\"   Train/Test Split: {len(X_train)}/{len(X_test)}\")\n",
    "\n",
    "print(f\"\\nü§ñ Model Training Results:\")\n",
    "print(f\"   Clear Model Accuracy: {accuracies[0]:.4f} ({accuracies[0]*100:.2f}%)\")\n",
    "print(f\"   FHE Model Accuracy: {accuracies[1]:.4f} ({accuracies[1]*100:.2f}%)\")\n",
    "print(f\"   Accuracy Difference: {abs(accuracies[0] - accuracies[1]):.4f}\")\n",
    "print(f\"   Prediction Agreement: {agreement_rate:.4f} ({agreement_rate*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\n‚ö° Performance Metrics:\")\n",
    "print(f\"   Clear Training Time: {clear_training_time:.2f} seconds\")\n",
    "print(f\"   FHE Training Time: {fhe_training_time:.2f} seconds\")\n",
    "if ENCRYPTED_INFERENCE_SUCCESS:\n",
    "    print(f\"   FHE Compilation Time: {compilation_time:.2f} seconds\")\n",
    "    print(f\"   Encrypted Inference: {fhe_inference_time:.2f} seconds ({n_encrypted_samples} samples)\")\n",
    "    print(f\"   Encryption Overhead: {(fhe_inference_time/n_encrypted_samples)/(clear_inference_time/len(X_test)):.0f}x slower\")\n",
    "\n",
    "print(f\"\\nüîí Privacy Analysis:\")\n",
    "print(f\"   FHE Mode: {'‚úÖ True Encryption' if ENCRYPTED_INFERENCE_SUCCESS else '‚ö†Ô∏è Simulation'}\")\n",
    "print(f\"   Data Privacy: {'‚úÖ Fully Protected' if ENCRYPTED_INFERENCE_SUCCESS else '‚ö†Ô∏è Not Encrypted'}\")\n",
    "print(f\"   Model Privacy: {'‚úÖ Encrypted Inference' if ENCRYPTED_INFERENCE_SUCCESS else '‚ö†Ô∏è Clear Inference'}\")\n",
    "\n",
    "print(f\"\\nüìà Key Insights:\")\n",
    "insights = []\n",
    "if abs(accuracies[0] - accuracies[1]) < 0.05:\n",
    "    insights.append(\"‚úÖ FHE model maintains high accuracy compared to clear model\")\n",
    "else:\n",
    "    insights.append(\"‚ö†Ô∏è FHE model shows some accuracy degradation\")\n",
    "\n",
    "if agreement_rate > 0.8:\n",
    "    insights.append(\"‚úÖ High agreement between clear and FHE predictions\")\n",
    "else:\n",
    "    insights.append(\"‚ö†Ô∏è Moderate agreement between clear and FHE predictions\")\n",
    "\n",
    "if ENCRYPTED_INFERENCE_SUCCESS:\n",
    "    insights.append(\"‚úÖ Successfully demonstrated true FHE encrypted inference\")\n",
    "    insights.append(\"‚úÖ Suitable for privacy-critical medical applications\")\n",
    "else:\n",
    "    insights.append(\"‚ö†Ô∏è Demonstrated FHE simulation mode\")\n",
    "    insights.append(\"üìù Consider installing Concrete-ML for true FHE capabilities\")\n",
    "\n",
    "for insight in insights:\n",
    "    print(f\"   {insight}\")\n",
    "\n",
    "print(f\"\\nüîÑ Next Steps:\")\n",
    "print(\"1. üîß Optimize FHE parameters for better performance\")\n",
    "print(\"2. üìä Evaluate on larger datasets\")\n",
    "print(\"3. üõ°Ô∏è Implement privacy-preserving SVM comparison\")\n",
    "print(\"4. üìà Generate comprehensive evaluation reports\")\n",
    "print(\"5. üîí Conduct security analysis of FHE implementation\")\n",
    "\n",
    "print(f\"\\n‚ú® FHE Training Demo completed successfully!\")\n",
    "print(f\"üìÅ Results saved to: {results_file}\")\n",
    "\n",
    "# Display final model comparison table\n",
    "print(f\"\\nüìã Final Model Comparison:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Metric':<25} {'Clear Model':<15} {'FHE Model':<15} {'Difference':<15}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Accuracy':<25} {accuracies[0]:<15.4f} {accuracies[1]:<15.4f} {abs(accuracies[0] - accuracies[1]):<15.4f}\")\n",
    "print(f\"{'Training Time (s)':<25} {clear_training_time:<15.2f} {fhe_training_time:<15.2f} {abs(clear_training_time - fhe_training_time):<15.2f}\")\n",
    "if ENCRYPTED_INFERENCE_SUCCESS:\n",
    "    print(f\"{'Inference Time (s/sample)':<25} {clear_inference_time/len(X_test):<15.6f} {fhe_inference_time/n_encrypted_samples:<15.6f} {abs((clear_inference_time/len(X_test)) - (fhe_inference_time/n_encrypted_samples)):<15.6f}\")\n",
    "print(f\"{'Privacy Level':<25} {'None':<15} {'High' if ENCRYPTED_INFERENCE_SUCCESS else 'Simulation':<15} {'-':<15}\")\n",
    "print(\"-\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
